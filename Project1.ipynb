{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Sentiment Analysis on Movie Reviews\n",
    "\n",
    "This project is an individual project. In this project, you are expected to solve the classification problem on movie reviews. Movie reviews have two different sentiments (positive or negative), please train machine learning or deep learning models to classify movie reviews into correct categories (1 for positive 1 and 0 for negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "* Please solve the problems in this notebook using the dataset `IBDM Dataset.csv`.\n",
    "* Important Dates: \n",
    "    * Project Start: Feb 19, Monday\n",
    "    * Project Due: March 7, Thursday midnight\n",
    "* Submission should include a pdf report (at least 4 pages) and code.\n",
    "* There are always last minute issues submitting the project. DO NOT WAIT UNTIL THE LAST MINUTE!\n",
    "\n",
    "**HINT:**\n",
    "* Here are some related tutorials that would be helpful:\n",
    "    * https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/code\n",
    "    * https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration: Exploring the Dataset\n",
    "\n",
    "To explore the data before preprocessing, we will go through the following exploration steps:\n",
    "\n",
    "1. Load the data to a pandas df\n",
    "2. Understand the structure, using mehods like info(), describe(), etc.\n",
    "3. Check for missing values\n",
    "4. Check the balance of the classes\n",
    "5. Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n",
      "\n",
      "Description:\n",
      "                                                    review sentiment\n",
      "count                                               50000     50000\n",
      "unique                                              49582         2\n",
      "top     Loved today's show!!! It was a variety and not...  positive\n",
      "freq                                                    5     25000\n",
      "\n",
      "First 5 rows:\n",
      "                                               review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "Missing Values:\n",
      " review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Sentiment Value Counts:\n",
      " sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHfCAYAAACyHslvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv8klEQVR4nO3de1iUdf7/8deAAqLOeAQkyWN5xLMi2lqufEWxg2WtppuHTC/7oqVsZu66pHawr/s1tdV0y5LadNeOVlgoYeIqeMI8J5umi6WoqTCCCgr3748u7q/z0w4oOvDh+biuuRbu+zM37+HaWZ87c9+Dw7IsSwAAAIbx8fYAAAAANwKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjVfH2AN5UXFyso0ePqmbNmnI4HN4eBwAA/AqWZens2bMKDQ2Vj89Pv15TqSPn6NGjCgsL8/YYAADgGhw5ckQNGzb8yf2VOnJq1qwp6cdfktPp9PI0AADg13C73QoLC7P/Hf8plTpySt6icjqdRA4AABXML51qwonHAADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjFSqyJk1a5a6du2qmjVrKigoSAMHDlRmZqbHmrvuuksOh8PjNm7cOI81WVlZGjBggAIDAxUUFKTJkyfr0qVLHmvWrVunTp06yd/fX82bN1dCQsIV8yxcuFCNGzdWQECAIiIitGXLltI8HAAAYLBSRU5qaqpiY2O1adMmJScn6+LFi+rbt6/y8/M91o0ZM0bHjh2zb7Nnz7b3FRUVacCAASosLFRaWpreeustJSQkKD4+3l5z6NAhDRgwQL1799aOHTs0ceJEPfbYY1q9erW9ZsWKFYqLi9Ozzz6r7du3q3379oqOjtaJEyeu9XcBAAAM4rAsy7rWO588eVJBQUFKTU1Vr169JP34Sk6HDh00b968q97n888/1913362jR48qODhYkrR48WJNmTJFJ0+elJ+fn6ZMmaJVq1Zpz5499v2GDBminJwcJSUlSZIiIiLUtWtXLViwQJJUXFyssLAwTZgwQc8888yvmt/tdsvlcik3N5e/Qg4AQAXxa//9vq5zcnJzcyVJderU8di+bNky1atXT23bttXUqVN17tw5e196errCw8PtwJGk6Ohoud1u7d27114TFRXlcczo6Gilp6dLkgoLC5WRkeGxxsfHR1FRUfaaqykoKJDb7fa4AQAAM1W51jsWFxdr4sSJ6tmzp9q2bWtvHzp0qBo1aqTQ0FDt2rVLU6ZMUWZmpj788ENJUnZ2tkfgSLK/z87O/tk1brdb58+f15kzZ1RUVHTVNfv37//JmWfNmqUZM2Zc60M2SuNnVnl7BNxEh18a4O0RcBPx/K5ceH7/tGuOnNjYWO3Zs0cbNmzw2D527Fj76/DwcDVo0EB9+vTRwYMH1axZs2uftAxMnTpVcXFx9vdut1thYWFenAgAANwo1xQ548ePV2JiotavX6+GDRv+7NqIiAhJ0oEDB9SsWTOFhIRccRXU8ePHJUkhISH2f5Zsu3yN0+lUtWrV5OvrK19f36uuKTnG1fj7+8vf3//XPUgAAFChleqcHMuyNH78eH300Udau3atmjRp8ov32bFjhySpQYMGkqTIyEjt3r3b4yqo5ORkOZ1OtW7d2l6TkpLicZzk5GRFRkZKkvz8/NS5c2ePNcXFxUpJSbHXAACAyq1Ur+TExsZq+fLl+vjjj1WzZk37HBqXy6Vq1arp4MGDWr58uWJiYlS3bl3t2rVLkyZNUq9evdSuXTtJUt++fdW6dWs98sgjmj17trKzszVt2jTFxsbar7KMGzdOCxYs0NNPP61HH31Ua9eu1bvvvqtVq/7vfea4uDiNGDFCXbp0Ubdu3TRv3jzl5+dr1KhRZfW7AQAAFVipImfRokWSfrxM/HJLly7VyJEj5efnpy+++MIOjrCwMA0aNEjTpk2z1/r6+ioxMVGPP/64IiMjVb16dY0YMUIzZ8601zRp0kSrVq3SpEmTNH/+fDVs2FBLlixRdHS0vWbw4ME6efKk4uPjlZ2drQ4dOigpKemKk5EBAEDldF2fk1PRVebPyeHqi8qFqy8qF57flUtlfH7flM/JAQAAKK+IHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYqVeTMmjVLXbt2Vc2aNRUUFKSBAwcqMzPTY82FCxcUGxurunXrqkaNGho0aJCOHz/usSYrK0sDBgxQYGCggoKCNHnyZF26dMljzbp169SpUyf5+/urefPmSkhIuGKehQsXqnHjxgoICFBERIS2bNlSmocDAAAMVqrISU1NVWxsrDZt2qTk5GRdvHhRffv2VX5+vr1m0qRJ+vTTT/Xee+8pNTVVR48e1QMPPGDvLyoq0oABA1RYWKi0tDS99dZbSkhIUHx8vL3m0KFDGjBggHr37q0dO3Zo4sSJeuyxx7R69Wp7zYoVKxQXF6dnn31W27dvV/v27RUdHa0TJ05cz+8DAAAYwmFZlnWtdz558qSCgoKUmpqqXr16KTc3V/Xr19fy5cv14IMPSpL279+vVq1aKT09Xd27d9fnn3+uu+++W0ePHlVwcLAkafHixZoyZYpOnjwpPz8/TZkyRatWrdKePXvsnzVkyBDl5OQoKSlJkhQREaGuXbtqwYIFkqTi4mKFhYVpwoQJeuaZZ646b0FBgQoKCuzv3W63wsLClJubK6fTea2/hgqp8TOrvD0CbqLDLw3w9gi4iXh+Vy6V8fntdrvlcrl+8d/v6zonJzc3V5JUp04dSVJGRoYuXryoqKgoe03Lli116623Kj09XZKUnp6u8PBwO3AkKTo6Wm63W3v37rXXXH6MkjUlxygsLFRGRobHGh8fH0VFRdlrrmbWrFlyuVz2LSws7HoePgAAKMeuOXKKi4s1ceJE9ezZU23btpUkZWdny8/PT7Vq1fJYGxwcrOzsbHvN5YFTsr9k38+tcbvdOn/+vH744QcVFRVddU3JMa5m6tSpys3NtW9Hjhwp/QMHAAAVQpVrvWNsbKz27NmjDRs2lOU8N5S/v7/8/f29PQYAALgJrumVnPHjxysxMVFffvmlGjZsaG8PCQlRYWGhcnJyPNYfP35cISEh9pr//2qrku9/aY3T6VS1atVUr149+fr6XnVNyTEAAEDlVqrIsSxL48eP10cffaS1a9eqSZMmHvs7d+6sqlWrKiUlxd6WmZmprKwsRUZGSpIiIyO1e/duj6ugkpOT5XQ61bp1a3vN5ccoWVNyDD8/P3Xu3NljTXFxsVJSUuw1AACgcivV21WxsbFavny5Pv74Y9WsWdM+/8XlcqlatWpyuVwaPXq04uLiVKdOHTmdTk2YMEGRkZHq3r27JKlv375q3bq1HnnkEc2ePVvZ2dmaNm2aYmNj7beSxo0bpwULFujpp5/Wo48+qrVr1+rdd9/VqlX/d8VAXFycRowYoS5duqhbt26aN2+e8vPzNWrUqLL63QAAgAqsVJGzaNEiSdJdd93lsX3p0qUaOXKkJGnu3Lny8fHRoEGDVFBQoOjoaL366qv2Wl9fXyUmJurxxx9XZGSkqlevrhEjRmjmzJn2miZNmmjVqlWaNGmS5s+fr4YNG2rJkiWKjo621wwePFgnT55UfHy8srOz1aFDByUlJV1xMjIAAKicrutzciq6X3udvYn4HI3KpTJ+jkZlxvO7cqmMz++b8jk5AAAA5RWRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACOVOnLWr1+ve+65R6GhoXI4HFq5cqXH/pEjR8rhcHjc+vXr57Hm9OnTGjZsmJxOp2rVqqXRo0crLy/PY82uXbv0m9/8RgEBAQoLC9Ps2bOvmOW9995Ty5YtFRAQoPDwcH322WelfTgAAMBQpY6c/Px8tW/fXgsXLvzJNf369dOxY8fs2z/+8Q+P/cOGDdPevXuVnJysxMRErV+/XmPHjrX3u91u9e3bV40aNVJGRob+8pe/aPr06XrttdfsNWlpaXr44Yc1evRoffXVVxo4cKAGDhyoPXv2lPYhAQAAA1Up7R369++v/v37/+waf39/hYSEXHXf119/raSkJG3dulVdunSRJP31r39VTEyM/vd//1ehoaFatmyZCgsL9eabb8rPz09t2rTRjh079PLLL9sxNH/+fPXr10+TJ0+WJD333HNKTk7WggULtHjx4tI+LAAAYJgbck7OunXrFBQUpBYtWujxxx/XqVOn7H3p6emqVauWHTiSFBUVJR8fH23evNle06tXL/n5+dlroqOjlZmZqTNnzthroqKiPH5udHS00tPTf3KugoICud1ujxsAADBTmUdOv3799PbbbyslJUX/8z//o9TUVPXv319FRUWSpOzsbAUFBXncp0qVKqpTp46ys7PtNcHBwR5rSr7/pTUl+69m1qxZcrlc9i0sLOz6HiwAACi3Sv121S8ZMmSI/XV4eLjatWunZs2aad26derTp09Z/7hSmTp1quLi4uzv3W43oQMAgKFu+CXkTZs2Vb169XTgwAFJUkhIiE6cOOGx5tKlSzp9+rR9Hk9ISIiOHz/usabk+19a81PnAkk/nivkdDo9bgAAwEw3PHK+++47nTp1Sg0aNJAkRUZGKicnRxkZGfaatWvXqri4WBEREfaa9evX6+LFi/aa5ORktWjRQrVr17bXpKSkePys5ORkRUZG3uiHBAAAKoBSR05eXp527NihHTt2SJIOHTqkHTt2KCsrS3l5eZo8ebI2bdqkw4cPKyUlRffdd5+aN2+u6OhoSVKrVq3Ur18/jRkzRlu2bNHGjRs1fvx4DRkyRKGhoZKkoUOHys/PT6NHj9bevXu1YsUKzZ8/3+OtpieffFJJSUmaM2eO9u/fr+nTp2vbtm0aP358GfxaAABARVfqyNm2bZs6duyojh07SpLi4uLUsWNHxcfHy9fXV7t27dK9996r22+/XaNHj1bnzp31r3/9S/7+/vYxli1bppYtW6pPnz6KiYnRHXfc4fEZOC6XS2vWrNGhQ4fUuXNn/eEPf1B8fLzHZ+n06NFDy5cv12uvvab27dvr/fff18qVK9W2bdvr+X0AAABDOCzLsrw9hLe43W65XC7l5uZWuvNzGj+zytsj4CY6/NIAb4+Am4jnd+VSGZ/fv/bfb/52FQAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACOVOnLWr1+ve+65R6GhoXI4HFq5cqXHfsuyFB8frwYNGqhatWqKiorSN99847Hm9OnTGjZsmJxOp2rVqqXRo0crLy/PY82uXbv0m9/8RgEBAQoLC9Ps2bOvmOW9995Ty5YtFRAQoPDwcH322WelfTgAAMBQpY6c/Px8tW/fXgsXLrzq/tmzZ+uVV17R4sWLtXnzZlWvXl3R0dG6cOGCvWbYsGHau3evkpOTlZiYqPXr12vs2LH2frfbrb59+6pRo0bKyMjQX/7yF02fPl2vvfaavSYtLU0PP/ywRo8era+++koDBw7UwIEDtWfPntI+JAAAYCCHZVnWNd/Z4dBHH32kgQMHSvrxVZzQ0FD94Q9/0FNPPSVJys3NVXBwsBISEjRkyBB9/fXXat26tbZu3aouXbpIkpKSkhQTE6PvvvtOoaGhWrRokf70pz8pOztbfn5+kqRnnnlGK1eu1P79+yVJgwcPVn5+vhITE+15unfvrg4dOmjx4sW/an632y2Xy6Xc3Fw5nc5r/TVUSI2fWeXtEXATHX5pgLdHwE3E87tyqYzP71/773eZnpNz6NAhZWdnKyoqyt7mcrkUERGh9PR0SVJ6erpq1aplB44kRUVFycfHR5s3b7bX9OrVyw4cSYqOjlZmZqbOnDljr7n855SsKfk5V1NQUCC32+1xAwAAZirTyMnOzpYkBQcHe2wPDg6292VnZysoKMhjf5UqVVSnTh2PNVc7xuU/46fWlOy/mlmzZsnlctm3sLCw0j5EAABQQVSqq6umTp2q3Nxc+3bkyBFvjwQAAG6QMo2ckJAQSdLx48c9th8/ftzeFxISohMnTnjsv3Tpkk6fPu2x5mrHuPxn/NSakv1X4+/vL6fT6XEDAABmKtPIadKkiUJCQpSSkmJvc7vd2rx5syIjIyVJkZGRysnJUUZGhr1m7dq1Ki4uVkREhL1m/fr1unjxor0mOTlZLVq0UO3ate01l/+ckjUlPwcAAFRupY6cvLw87dixQzt27JD048nGO3bsUFZWlhwOhyZOnKjnn39en3zyiXbv3q3hw4crNDTUvgKrVatW6tevn8aMGaMtW7Zo48aNGj9+vIYMGaLQ0FBJ0tChQ+Xn56fRo0dr7969WrFihebPn6+4uDh7jieffFJJSUmaM2eO9u/fr+nTp2vbtm0aP3789f9WAABAhVeltHfYtm2bevfubX9fEh4jRoxQQkKCnn76aeXn52vs2LHKycnRHXfcoaSkJAUEBNj3WbZsmcaPH68+ffrIx8dHgwYN0iuvvGLvd7lcWrNmjWJjY9W5c2fVq1dP8fHxHp+l06NHDy1fvlzTpk3TH//4R912221auXKl2rZte02/CAAAYJbr+pycio7PyUFlURk/R6My4/lduVTG57dXPicHAACgvCByAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGKnMI2f69OlyOBwet5YtW9r7L1y4oNjYWNWtW1c1atTQoEGDdPz4cY9jZGVlacCAAQoMDFRQUJAmT56sS5cueaxZt26dOnXqJH9/fzVv3lwJCQll/VAAAEAFdkNeyWnTpo2OHTtm3zZs2GDvmzRpkj799FO99957Sk1N1dGjR/XAAw/Y+4uKijRgwAAVFhYqLS1Nb731lhISEhQfH2+vOXTokAYMGKDevXtrx44dmjhxoh577DGtXr36RjwcAABQAVW5IQetUkUhISFXbM/NzdUbb7yh5cuX67e//a0kaenSpWrVqpU2bdqk7t27a82aNdq3b5+++OILBQcHq0OHDnruuec0ZcoUTZ8+XX5+flq8eLGaNGmiOXPmSJJatWqlDRs2aO7cuYqOjv7JuQoKClRQUGB/73a7y/iRAwCA8uKGvJLzzTffKDQ0VE2bNtWwYcOUlZUlScrIyNDFixcVFRVlr23ZsqVuvfVWpaenS5LS09MVHh6u4OBge010dLTcbrf27t1rr7n8GCVrSo7xU2bNmiWXy2XfwsLCyuTxAgCA8qfMIyciIkIJCQlKSkrSokWLdOjQIf3mN7/R2bNnlZ2dLT8/P9WqVcvjPsHBwcrOzpYkZWdnewROyf6SfT+3xu126/z58z8529SpU5Wbm2vfjhw5cr0PFwAAlFNl/nZV//797a/btWuniIgINWrUSO+++66qVatW1j+uVPz9/eXv7+/VGQAAwM1xwy8hr1Wrlm6//XYdOHBAISEhKiwsVE5Ojsea48eP2+fwhISEXHG1Vcn3v7TG6XR6PaQAAED5cMMjJy8vTwcPHlSDBg3UuXNnVa1aVSkpKfb+zMxMZWVlKTIyUpIUGRmp3bt368SJE/aa5ORkOZ1OtW7d2l5z+TFK1pQcAwAAoMwj56mnnlJqaqoOHz6stLQ03X///fL19dXDDz8sl8ul0aNHKy4uTl9++aUyMjI0atQoRUZGqnv37pKkvn37qnXr1nrkkUe0c+dOrV69WtOmTVNsbKz9VtO4ceP07bff6umnn9b+/fv16quv6t1339WkSZPK+uEAAIAKqszPyfnuu+/08MMP69SpU6pfv77uuOMObdq0SfXr15ckzZ07Vz4+Pho0aJAKCgoUHR2tV1991b6/r6+vEhMT9fjjjysyMlLVq1fXiBEjNHPmTHtNkyZNtGrVKk2aNEnz589Xw4YNtWTJkp+9fBwAAFQuDsuyLG8P4S1ut1sul0u5ublyOp3eHuemavzMKm+PgJvo8EsDvD0CbiKe35VLZXx+/9p/v/nbVQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxU4SNn4cKFaty4sQICAhQREaEtW7Z4eyQAAFAOVOjIWbFiheLi4vTss89q+/btat++vaKjo3XixAlvjwYAALysQkfOyy+/rDFjxmjUqFFq3bq1Fi9erMDAQL355pveHg0AAHhZFW8PcK0KCwuVkZGhqVOn2tt8fHwUFRWl9PT0q96noKBABQUF9ve5ubmSJLfbfWOHLYeKC855ewTcRJXxv+OVGc/vyqUyPr9LHrNlWT+7rsJGzg8//KCioiIFBwd7bA8ODtb+/fuvep9Zs2ZpxowZV2wPCwu7ITMC5YVrnrcnAHCjVObn99mzZ+VyuX5yf4WNnGsxdepUxcXF2d8XFxfr9OnTqlu3rhwOhxcnw83gdrsVFhamI0eOyOl0enscAGWI53flYlmWzp49q9DQ0J9dV2Ejp169evL19dXx48c9th8/flwhISFXvY+/v7/8/f09ttWqVetGjYhyyul08j+CgKF4flceP/cKTokKe+Kxn5+fOnfurJSUFHtbcXGxUlJSFBkZ6cXJAABAeVBhX8mRpLi4OI0YMUJdunRRt27dNG/ePOXn52vUqFHeHg0AAHhZhY6cwYMH6+TJk4qPj1d2drY6dOigpKSkK05GBqQf36589tlnr3jLEkDFx/MbV+Owfun6KwAAgAqowp6TAwAA8HOIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAFChFRYWKjMzU5cuXfL2KChniBwY71//+pd+//vfKzIyUt9//70k6e9//7s2bNjg5ckAXI9z585p9OjRCgwMVJs2bZSVlSVJmjBhgl566SUvT4fygMiB0T744ANFR0erWrVq+uqrr1RQUCBJys3N1Ysvvujl6QBcj6lTp2rnzp1at26dAgIC7O1RUVFasWKFFydDeUHkwGjPP/+8Fi9erNdff11Vq1a1t/fs2VPbt2/34mQArtfKlSu1YMEC3XHHHXI4HPb2Nm3a6ODBg16cDOUFkQOjZWZmqlevXldsd7lcysnJufkDASgzJ0+eVFBQ0BXb8/PzPaIHlReRA6OFhITowIEDV2zfsGGDmjZt6oWJAJSVLl26aNWqVfb3JWGzZMkSRUZGemsslCMV+q+QA79kzJgxevLJJ/Xmm2/K4XDo6NGjSk9P11NPPaU///nP3h4PwHV48cUX1b9/f+3bt0+XLl3S/PnztW/fPqWlpSk1NdXb46Ec4K+Qw2iWZenFF1/UrFmzdO7cOUmSv7+/nnrqKT333HNeng7A9Tp48KBeeukl7dy5U3l5eerUqZOmTJmi8PBwb4+GcoDIQaVQWFioAwcOKC8vT61bt1aNGjW8PRIA4AbjnBwY7Z133tG5c+fk5+en1q1bq1u3bgQOYIioqCglJCTI7XZ7exSUU0QOjDZp0iQFBQVp6NCh+uyzz1RUVOTtkQCUkTZt2mjq1KkKCQnRQw89pI8//lgXL1709lgoR4gcGO3YsWP65z//KYfDod/97ndq0KCBYmNjlZaW5u3RAFyn+fPn6/vvv9fKlStVvXp1DR8+XMHBwRo7diwnHkMS5+SgEjl37pw++ugjLV++XF988YUaNmzIB4YBBrlw4YI+/fRTvfDCC9q9ezev3IJLyFF5BAYGKjo6WmfOnNF//vMfff31194eCUAZyc7O1j//+U+988472rVrl7p16+btkVAO8HYVjHfu3DktW7ZMMTExuuWWWzRv3jzdf//92rt3r7dHA3Ad3G63li5dqv/6r/9SWFiYFi1apHvvvVfffPONNm3a5O3xUA7wdhWMNmTIECUmJiowMFC/+93vNGzYMD4JFTBEtWrVVLt2bQ0ePFjDhg1Tly5dvD0SyhneroLRfH199e677yo6Olq+vr7eHgdAGfrkk0/Up08f+fjwpgSujldyAACAkXglB8Z55ZVXNHbsWAUEBOiVV1752bVPPPHETZoKQFno1KmTUlJSVLt2bXXs2PFn/9r49u3bb+JkKI+IHBhn7ty5GjZsmAICAjR37tyfXOdwOIgcoIK577775O/vb3/9c5ED8HYVAAAwEmdrwWgzZ860//r45c6fP6+ZM2d6YSIAZaVp06Y6derUFdtzcnLUtGlTL0yE8oZXcmA0X19fHTt2TEFBQR7bT506paCgID4RFajAfHx8lJ2dfcXz+/jx4woLC1NhYaGXJkN5wTk5MJplWVd9z37nzp2qU6eOFyYCcL0++eQT++vVq1fL5XLZ3xcVFSklJUVNmjTxxmgoZ4gcGKl27dpyOBxyOBy6/fbbPUKnqKhIeXl5GjdunBcnBHCtBg4cKOnHiwdGjBjhsa9q1apq3Lix5syZ44XJUN7wdhWM9NZbb8myLD366KOaN2+ex//T8/PzU+PGjfnkY6CCa9KkibZu3ap69ep5exSUU0QOjJaamqoePXqoatWq3h4FAHCTETkwjtvtltPptL/+OSXrAFRM+fn5Sk1NVVZW1hUnGvM5WCByYJzLr6jy8fG56onHJSckc3UVUHF99dVXiomJ0blz55Sfn686derohx9+UGBgoIKCgvTtt996e0R4GScewzhr1661r5z68ssvvTwNgBtl0qRJuueee7R48WK5XC5t2rRJVatW1e9//3s9+eST3h4P5QCv5AAAKqRatWpp8+bNatGihWrVqqX09HS1atVKmzdv1ogRI7R//35vjwgv4xOPYbSkpCRt2LDB/n7hwoXq0KGDhg4dqjNnznhxMgDXq2rVqvLx+fGfsaCgIGVlZUmSXC6Xjhw54s3RUE4QOTDa5MmT7ZOPd+/erbi4OMXExOjQoUOKi4vz8nQArkfHjh21detWSdKdd96p+Ph4LVu2TBMnTlTbtm29PB3KA96ugtFq1KihPXv2qHHjxpo+fbr27Nmj999/X9u3b1dMTIyys7O9PSKAa7Rt2zadPXtWvXv31okTJzR8+HClpaXptttu05tvvqn27dt7e0R4GScew2h+fn72H+j84osvNHz4cElSnTp1fvHycgDlW5cuXeyvg4KClJSU5MVpUB4ROTDaHXfcobi4OPXs2VNbtmzRihUrJEn//ve/1bBhQy9PBwC4kYgcGG3BggX67//+b73//vtatGiRbrnlFknS559/rn79+nl5OgDXo2PHjlf9HCyHw6GAgAA1b95cI0eOVO/evb0wHcoDzskBAFRIU6dO1aJFixQeHq5u3bpJkrZu3apdu3Zp5MiR2rdvn1JSUvThhx/qvvvu8/K08AYiB8YrKirSypUr9fXXX0uS2rRpo3vvvVe+vr5engzA9RgzZoxuvfVW/fnPf/bY/vzzz+s///mPXn/9dT377LNatWqVtm3b5qUp4U1EDox24MABxcTE6Pvvv1eLFi0kSZmZmQoLC9OqVavUrFkzL08I4Fq5XC5lZGSoefPmHtsPHDigzp07Kzc3V/v371fXrl119uxZL00Jb+JzcmC0J554Qs2aNdORI0e0fft2bd++XVlZWWrSpAl/vA+o4AICApSWlnbF9rS0NAUEBEiSiouL7a9R+XDiMYyWmpqqTZs22X/LSpLq1q2rl156ST179vTiZACu14QJEzRu3DhlZGSoa9eukn48J2fJkiX64x//KElavXq1OnTo4MUp4U28XQWj1alTR4mJierRo4fH9o0bN+qee+7R6dOnvTQZgLKwbNkyLViwQJmZmZKkFi1aaMKECRo6dKgk6fz58/bVVqh8iBwYbfjw4dq+fbveeOMN++qLzZs3a8yYMercubMSEhK8OyAA4IbhnBwY7ZVXXlGzZs0UGRmpgIAABQQEqEePHmrevLnmz5/v7fEAXKecnBz77amSV2a3b9+u77//3suToTzglRxUCgcOHNC+ffskSa1bt77iagwAFc+uXbsUFRUll8ulw4cPKzMzU02bNtW0adOUlZWlt99+29sjwst4JQfGe+ONNzRw4EA99NBDeuihhzRw4EAtWbLE22MBuE5xcXEaOXKkvvnmG49zbmJiYrR+/XovTobygqurYLT4+Hi9/PLLmjBhgiIjIyVJ6enpmjRpkrKysjRz5kwvTwjgWm3dulV/+9vfrth+yy23KDs72wsTobwhcmC0RYsW6fXXX9fDDz9sb7v33nvVrl07TZgwgcgBKjB/f3+53e4rtv/73/9W/fr1vTARyhveroLRLl68qC5dulyxvXPnzrp06ZIXJgJQVu69917NnDlTFy9elPTjH+bMysrSlClTNGjQIC9Ph/KAyIHRHnnkES1atOiK7a+99pqGDRvmhYkAlJU5c+YoLy9PQUFBOn/+vO688041b95cNWrU0AsvvODt8VAOcHUVjDZhwgS9/fbbCgsLU/fu3SX9+Dk5WVlZGj58uKpWrWqvffnll701JoDrsHHjRu3cuVN5eXnq1KmToqKivD0SygkiB0br3bv3r1rncDi0du3aGzwNgLKWkpKilJQUnThxQsXFxR773nzzTS9NhfKCE49htC+//NLbIwC4QWbMmKGZM2eqS5cuatCggRwOh7dHQjnDKzkAgAqpQYMGmj17th555BFvj4JyihOPAQAVUmFh4RV/fBe4HJEDAKiQHnvsMS1fvtzbY6Ac45wcAECFdOHCBb322mv64osv1K5dO4+rJSWumATn5AAAKqifu3qSKyYhETkAAMBQnJMDAACMROQAAAAjETkAAMBIRA4AADASkQPACI0bN9a8efO8PQaAcoTIAVChJCQkqFatWlds37p1q8aOHXvzB/r/rFu3Tg6HQzk5Od4eBaj0+DBAAEaoX7++t0cAUM7wSg6AMvf+++8rPDxc1apVU926dRUVFaX8/HxJ0pIlS9SqVSsFBASoZcuWevXVV+37HT58WA6HQx9++KF69+6twMBAtW/fXunp6ZJ+fJVk1KhRys3NlcPhkMPh0PTp0yVd+XaVw+HQ3/72N919990KDAxUq1atlJ6ergMHDuiuu+5S9erV1aNHDx08eNBj9o8//lidOnVSQECAmjZtqhkzZujSpUsex12yZInuv/9+BQYG6rbbbtMnn3xiz1/yAXW1a9eWw+HQyJEjy/rXC+DXsgCgDB09etSqUqWK9fLLL1uHDh2ydu3aZS1cuNA6e/as9c4771gNGjSwPvjgA+vbb7+1PvjgA6tOnTpWQkKCZVmWdejQIUuS1bJlSysxMdHKzMy0HnzwQatRo0bWxYsXrYKCAmvevHmW0+m0jh07Zh07dsw6e/asZVmW1ahRI2vu3Ln2HJKsW265xVqxYoWVmZlpDRw40GrcuLH129/+1kpKSrL27dtnde/e3erXr599n/Xr11tOp9NKSEiwDh48aK1Zs8Zq3LixNX36dI/jNmzY0Fq+fLn1zTffWE888YRVo0YN69SpU9alS5esDz74wJJkZWZmWseOHbNycnJuzi8ewBWIHABlKiMjw5JkHT58+Ip9zZo1s5YvX+6x7bnnnrMiIyMty/q/yFmyZIm9f+/evZYk6+uvv7Ysy7KWLl1quVyuK459tciZNm2a/X16erolyXrjjTfsbf/4xz+sgIAA+/s+ffpYL774osdx//73v1sNGjT4yePm5eVZkqzPP//csizL+vLLLy1J1pkzZ66YEcDNxTk5AMpU+/bt1adPH4WHhys6Olp9+/bVgw8+KD8/Px08eFCjR4/WmDFj7PWXLl2Sy+XyOEa7du3srxs0aCBJOnHihFq2bFmqWS4/TnBwsCQpPDzcY9uFCxfkdrvldDq1c+dObdy4US+88IK9pqioSBcuXNC5c+cUGBh4xXGrV68up9OpEydOlGo2ADcekQOgTPn6+io5OVlpaWlas2aN/vrXv+pPf/qTPv30U0nS66+/roiIiCvuc7nL/5q0w+GQJBUXF5d6lqsd5+eOnZeXpxkzZuiBBx644lgBAQFXPW7Jca5lPgA3FpEDoMw5HA717NlTPXv2VHx8vBo1aqSNGzcqNDRU3377rYYNG3bNx/bz81NRUVEZTvt/OnXqpMzMTDVv3vyaj+Hn5ydJN2xGAL8ekQOgTG3evFkpKSnq27evgoKCtHnzZp08eVKtWrXSjBkz9MQTT8jlcqlfv34qKCjQtm3bdObMGcXFxf2q4zdu3Fh5eXlKSUlR+/btFRgYaL+NdL3i4+N1991369Zbb9WDDz4oHx8f7dy5U3v27NHzzz//q47RqFEjORwOJSYmKiYmRtWqVVONGjXKZD4ApcMl5ADKlNPp1Pr16xUTE6Pbb79d06ZN05w5c9S/f3899thjWrJkiZYuXarw8HDdeeedSkhIUJMmTX718Xv06KFx48Zp8ODBql+/vmbPnl1ms0dHRysxMVFr1qxR165d1b17d82dO1eNGjX61ce45ZZbNGPGDD3zzDMKDg7W+PHjy2w+AKXjsCzL8vYQAAAAZY1XcgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABjp/wFIr6IJEKEXAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Understand the structure of the data\n",
    "print(df.info())\n",
    "print('\\nDescription:\\n', df.describe())\n",
    "print('\\nFirst 5 rows:\\n', df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print('\\nMissing Values:\\n', df.isnull().sum())\n",
    "\n",
    "# Check the balance of the data\n",
    "print('\\nSentiment Value Counts:\\n', df['sentiment'].value_counts())\n",
    "\n",
    "# Visualize the data\n",
    "df['sentiment'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis, there are a few key takeaways:\n",
    "\n",
    "1. Size: Dataset contains 50,000 entries, each with a review an a sentiment\n",
    "2. No missing values: Both columns contain equal number of values -- so no need to handle any missing entries\n",
    "3. Unique reviews: There are 49,582 unique reviews, meaning some of the reviews are duplicates but most are unique\n",
    "4. Balance: The dataset is perfectly balanced, with 25,000 positive and 25,000 negative reviews\n",
    "\n",
    "In summary, the dataset seems to be clean and well balanced. Next, we will move onto preprocessing the text data for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preproccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some common preproccessing steps, feel free to add more preproccessing steps if needed: \n",
    "1. check missing values. \n",
    "2. remove noise and special characters, such as \"\\[[^]]*\\]\", etc.\n",
    "3. transform all words to lower case, \n",
    "4. word tokenization  \n",
    "5. stop words removing and stemming,\n",
    "6. divide the dataset into train set (75%) and test set (25%) with random sampling\n",
    "\n",
    " ......\n",
    "\n",
    "**Hint:**\n",
    "* You may need TfidVectorizer class to convert a collection of raw documents to a matrix of TF-IDF features: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html, \n",
    "* You are also welcome to use the Python Natural Language Processing Toolkit (www.nltk.org).\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the necessary modules, we will now begin preprocessing our data for feature extraction. For stemming, we will use PorterStemmer from the NLTK package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owenc\\AppData\\Local\\Temp\\ipykernel_22292\\2316146534.py:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch 1 oz episod 'll hook ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product . film techniqu unassumin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic 's famili littl boy ( jake ) think 's zo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei 's `` love time money '' visual ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movi right good job . n't creativ orig...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot , bad dialogu , bad act , idiot direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>cathol taught parochi elementari school nun , ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>'m go disagre previou comment side maltin one ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expect star trek movi high art , fan expec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one review mention watch 1 oz episod 'll hook ...  positive\n",
       "1      wonder littl product . film techniqu unassumin...  positive\n",
       "2      thought wonder way spend time hot summer weeke...  positive\n",
       "3      basic 's famili littl boy ( jake ) think 's zo...  negative\n",
       "4      petter mattei 's `` love time money '' visual ...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought movi right good job . n't creativ orig...  positive\n",
       "49996  bad plot , bad dialogu , bad act , idiot direc...  negative\n",
       "49997  cathol taught parochi elementari school nun , ...  negative\n",
       "49998  'm go disagre previou comment side maltin one ...  negative\n",
       "49999  one expect star trek movi high art , fan expec...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    # Removing noise and special chars\n",
    "    text = re.sub(\"\\[[^]]*\\]\", \"\", text)\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    text = word_tokenize(text)\n",
    "    # Stemming/stop word removal\n",
    "    text = [stemmer.stem(word) for word in text if word not in stop_words]\n",
    "\n",
    "    return ' '.join(text)\n",
    "\n",
    "# Apply the function to the review column of our df\n",
    "df['review'] = df['review'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the above output to ensure proper preprocessing:\n",
    "- all text is lowercased\n",
    "- no apparent html tags, special characters\n",
    "- text appears to be stemmed\n",
    "\n",
    "From here, we will use TfidVectorizer to fit and transform the preprocessed reviews. This converts the text data into a matrix of TF-IDF features. This matrix reflects the importance of a specific word is to a document in a collection or corpus (search).\n",
    "\n",
    "Fitting the vectorizer on our review column means it is learning the vocabulary of the dataset. It is then transformed into a numerical vector which reflects the importance of a word in a particular document.\n",
    "\n",
    "The importance of using vectorization is that it converts text data, which is unstructured, into a structured form that can be used as input to a machine learning model. Machine learning algorithms work with numerical data, and vectorization methods convert text into numerical data while preserving the semantic relationship between words.\n",
    "\n",
    "After vectorization, the data is split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:  37500\n",
      "Test set size:  12500\n"
     ]
    }
   ],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "\n",
    "# Map the sentiment to 1 and 0 and set our target variable\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the data. 75% for training and 25% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Train set size: \", X_train.shape[0])\n",
    "print(\"Test set size: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale behind preprocessing steps:**\n",
    "\n",
    "    preprocess_text() function:\n",
    "\n",
    "We define a seperate preprocess_text() function which handles all of our text preprocessing steps. Some of these steps could have been passed as parameters when initializing our TfidfVectorizer -- however by defining a seperate funciton, we maintain more control over the process. For example, the vectorizer has built in options for lowercasing, tokenization, and some others, but it does not have the same stemming capabilities. Thus, we elect to handle all of our preprocessing steps in one function, including using PorterStemmer.\n",
    "\n",
    "\n",
    "    TfidfVectorizer() Initialization and Default Parameters:\n",
    "\n",
    "While TfidfVectorizer() has many built in init parameters, I've elected to use the default parameters for the following reason: Fine tuning would likely involve using grid search or cross validation to give us our optimal parameters. However, this is a computationally intensive process and would require seperate analysis for each of our ML models. For our sake, the default parameters will likely not harm our model performance enough to justify computing optimal parameters for each specific model. \n",
    "\n",
    "Now that we have our training and test sets, we can move on to model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling\n",
    "\n",
    "* Please use the following models to classify the data:\n",
    "    * Logistic Regression\n",
    "    * LinearSVC\n",
    "    * KNeighborsClassifier\n",
    "    * Fully-connected layers, please try different number of hidden layers, different values of \"hidden_layer_sizes\" and \"activation\".\n",
    "    * CNN (please use different number of convolutional layers combined with different number of fully-connected layers, and compare the results).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      6157\n",
      "           1       0.88      0.90      0.89      6343\n",
      "\n",
      "    accuracy                           0.89     12500\n",
      "   macro avg       0.89      0.89      0.89     12500\n",
      "weighted avg       0.89      0.89      0.89     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the mode\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\owenc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      6157\n",
      "           1       0.89      0.90      0.89      6343\n",
      "\n",
      "    accuracy                           0.89     12500\n",
      "   macro avg       0.89      0.89      0.89     12500\n",
      "weighted avg       0.89      0.89      0.89     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize the model\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\owenc\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\owenc\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      6157\n",
      "           1       0.76      0.85      0.80      6343\n",
      "\n",
      "    accuracy                           0.78     12500\n",
      "   macro avg       0.79      0.78      0.78     12500\n",
      "weighted avg       0.79      0.78      0.78     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the model using 5 nearest neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79      6157\n",
      "           1       0.79      0.81      0.80      6343\n",
      "\n",
      "    accuracy                           0.79     12500\n",
      "   macro avg       0.79      0.79      0.79     12500\n",
      "weighted avg       0.79      0.79      0.79     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model using 10 nearest neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# Fit the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layers\n",
    "\n",
    "To test out different initialization parameters, we will first use grid search to find the optimal parameters for our model.\n",
    "\n",
    "Grid search is a hyperparameter tuning technique to find the optimal parameters for a model. It involves defining a grid of hyperparameters and training a model on every combination of these hyperparameters. Each model is then evaluated on a validation set using cross validation. \n",
    "\n",
    "Grid search can be computationally intensive, so for our case we will first define our grid to be \n",
    "\n",
    "        {'hidden_layer_sizes': [(100,), (100, 50), (100, 50, 25)], 'activation': ['relu', 'tanh']}\n",
    "\n",
    "\n",
    "Giving us 3 * 2 = 6 combinations of our parameters. We would be able to test more parameters if we had access to greater computing power.\n",
    "\n",
    "Depending on how this performs, we may come back and test new parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m mlp_grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Print best params and best score\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgrid_search\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define our parameter grid\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (100,50), (100,50,25)],\n",
    "    'activation': ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "# Initialize grid search\n",
    "mlp_grid_search = GridSearchCV(MLPClassifier(random_state=42), mlp_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "# Perform grid search\n",
    "mlp_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* Ignore error, small typo when printing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'hidden_layer_sizes': (100, 50)}\n",
      "0.8732266666666666\n"
     ]
    }
   ],
   "source": [
    "# Print best params and best score\n",
    "print(mlp_grid_search.best_params_)\n",
    "print(mlp_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      6157\n",
      "           1       0.87      0.88      0.88      6343\n",
      "\n",
      "    accuracy                           0.87     12500\n",
      "   macro avg       0.87      0.87      0.87     12500\n",
      "weighted avg       0.87      0.87      0.87     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_model = mlp_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "To implement CNN, we'll use numpy, TensorFlow and Keras to test the model with different combinations of convolutional and fully connected layers.\n",
    "\n",
    "This will require some further data preprocessing steps to prepare it for a CNN model. Previously, we converted the raw text data to a matrix of TF-IDF features. This is suitable for the other models we trained, but will not work for CNN. The previous models treated each document as a \"bag of words\", but CNN considers sequence of the words as well.\n",
    "\n",
    "To preprocess our data, we will take the following steps:\n",
    "\n",
    "1. Tokenization: We will first tokenize our words and convert to numerical format. The parameter 'num_words' is set to 5000, meaning we are only concerned with the 5000 most frequent words in our document.\n",
    "2. Padding: After tokenization, each review will be converted to a sequence of integers. Neural networks require that each input is the same length, so we will ensure that each of our reviews are of the same length.\n",
    "3. Labels to Array: We will lastly convert our 'sentiment' labels to a numpy array since this is the required format for CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize tokenizer with 5000 word vocab size\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "\n",
    "# Pad sequences such that they all have the same length\n",
    "\n",
    "# max_length = max([len(sequence) for sequence in sequences])\n",
    "# **Adjust padding sequences as needed**\n",
    "X = pad_sequences(sequences, maxlen=500)\n",
    "\n",
    "# Convert sentiments to numpy array\n",
    "y = df['sentiment'].values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready to train a CNN for text classification. We want to test different combinations of convolutional and fully connected layers. To do so, we will define a function which takes number of layers as input and returns a compiled CNN model. This will allow us to test differnt combinations efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten\n",
    "\n",
    "def create_cnn_model(num_conv_layers, num_dense_layers, vocab_size=5000, embedding_dim=50, max_length=100):\n",
    "    # Initialize the mode\n",
    "    model = Sequential()\n",
    "    # Add embedding layer\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "\n",
    "    # Add convolutional layers using 128 filters of size 5 and relu activation\n",
    "    # This is a common starting point and may be fine tuned later\n",
    "    for _ in range(num_conv_layers):\n",
    "        model.add(Conv1D(128, 5, activation='relu'))\n",
    "\n",
    "    # Add global max pooling layer\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    # Add dense layers with 10 units and relu activation\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "\n",
    "    # Add output layer with 1 unit and sigmoid activation, so that output is between 0 and 1\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model using adam optimizer and binary crossentropy loss\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1172/1172 [==============================] - 82s 69ms/step - loss: 0.4217 - accuracy: 0.7831 - val_loss: 0.3083 - val_accuracy: 0.8665\n",
      "Epoch 2/8\n",
      "1172/1172 [==============================] - 87s 74ms/step - loss: 0.2521 - accuracy: 0.8983 - val_loss: 0.2807 - val_accuracy: 0.8828\n",
      "Epoch 3/8\n",
      "1172/1172 [==============================] - 87s 74ms/step - loss: 0.1749 - accuracy: 0.9352 - val_loss: 0.2952 - val_accuracy: 0.8832\n",
      "Epoch 4/8\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 0.1100 - accuracy: 0.9625 - val_loss: 0.3547 - val_accuracy: 0.8772\n",
      "Epoch 5/8\n",
      "1172/1172 [==============================] - 93s 80ms/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.4452 - val_accuracy: 0.8698\n",
      "Epoch 6/8\n",
      "1172/1172 [==============================] - 91s 78ms/step - loss: 0.0476 - accuracy: 0.9842 - val_loss: 0.4821 - val_accuracy: 0.8740\n",
      "Epoch 7/8\n",
      "1172/1172 [==============================] - 94s 80ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.6409 - val_accuracy: 0.8546\n",
      "Epoch 8/8\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.5561 - val_accuracy: 0.8709\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 0.5561 - accuracy: 0.8709\n",
      "CNN Model Accuracy: 87.09%\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(sequence) for sequence in sequences])\n",
    "\n",
    "cnn_model = create_cnn_model(2, 2, max_length=500)\n",
    "\n",
    "# Fit the model\n",
    "cnn_model.fit(X_train, y_train, epochs=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'CNN Model Accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Model Tuning:\n",
    "\n",
    "Before testing different combinations of convolutional and full connected layers, we experiment with the max length parameter. This determines how long our sequences will be. For example, setting max_lenth at 100 will only take the first 100 words of a review, whereas setting max_length to the max length of any sequence in 'sequences' will include every word from every review. These were the results:\n",
    "\n",
    "Results for max length = 100 Sequences, 10 epochs:\n",
    "CNN Model Accuracy: 85.34%\n",
    "\n",
    "Results for max length = 200, 10 epochs:\n",
    "CNN Model Accuracy: 87.23%\n",
    "\n",
    "Results for max length = 500, 8 epochs:\n",
    "CNN Model Accuracy: 87.09%\n",
    "\n",
    "Results for max length = 1128 (max length of sequence), 5 epochs:\n",
    "CNN Model Accuracy: 87.34%\n",
    "\n",
    "So, by increasing our max length, we aren't necessarily improving the accuracy. Using 200 words gives the model enough information about the review to evaluate its sentiment while saving computational cost.\n",
    "\n",
    "To test different numbers of layers, we'll use 200 sequences and 500 sequences. We will also introduce early stopping criteria such that a model will stop training if it does not show improvement for 2 consecutive epochs. This will save some computational cost. We'll use combinations of 1-3 convoluational/dense layers to train the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 19s 15ms/step - loss: 0.3728 - accuracy: 0.8289 - val_loss: 0.2841 - val_accuracy: 0.8818\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.2167 - accuracy: 0.9154 - val_loss: 0.2784 - val_accuracy: 0.8863\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.1283 - accuracy: 0.9547 - val_loss: 0.3013 - val_accuracy: 0.8860\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0535 - accuracy: 0.9853 - val_loss: 0.3757 - val_accuracy: 0.8813\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0175 - accuracy: 0.9970 - val_loss: 0.4483 - val_accuracy: 0.8832\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.5193 - val_accuracy: 0.8822\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.6095 - val_accuracy: 0.8822\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.6617 - val_accuracy: 0.8778\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 18s 15ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.6936 - val_accuracy: 0.8810\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.7370 - val_accuracy: 0.8798\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.7370 - accuracy: 0.8798\n",
      "CNN Model with 1 conv layers and 1 dense layers Accuracy: 87.98%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 19s 15ms/step - loss: 0.3692 - accuracy: 0.8321 - val_loss: 0.2736 - val_accuracy: 0.8860\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.2088 - accuracy: 0.9190 - val_loss: 0.2891 - val_accuracy: 0.8825\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.1130 - accuracy: 0.9611 - val_loss: 0.3357 - val_accuracy: 0.8777\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.0414 - accuracy: 0.9888 - val_loss: 0.4312 - val_accuracy: 0.8825\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 19s 16ms/step - loss: 0.0196 - accuracy: 0.9956 - val_loss: 0.4878 - val_accuracy: 0.8754\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 18s 15ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.5398 - val_accuracy: 0.8769\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 18s 16ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5969 - val_accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 19s 17ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.6664 - val_accuracy: 0.8794\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 18s 15ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.6874 - val_accuracy: 0.8781\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 18s 16ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.6647 - val_accuracy: 0.8793\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.6647 - accuracy: 0.8793\n",
      "CNN Model with 1 conv layers and 2 dense layers Accuracy: 87.93%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 19s 16ms/step - loss: 0.3896 - accuracy: 0.8078 - val_loss: 0.2847 - val_accuracy: 0.8791\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.2203 - accuracy: 0.9133 - val_loss: 0.2694 - val_accuracy: 0.8894\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 17s 14ms/step - loss: 0.1332 - accuracy: 0.9545 - val_loss: 0.3273 - val_accuracy: 0.8799\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0593 - accuracy: 0.9833 - val_loss: 0.3825 - val_accuracy: 0.8814\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 18s 15ms/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 0.4546 - val_accuracy: 0.8784\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.4790 - val_accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 18s 15ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.5497 - val_accuracy: 0.8767\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 18s 15ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.5636 - val_accuracy: 0.8762\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 17s 15ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.6164 - val_accuracy: 0.8765\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 18s 16ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.7334 - val_accuracy: 0.8750\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.7334 - accuracy: 0.8750\n",
      "CNN Model with 1 conv layers and 3 dense layers Accuracy: 87.50%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 39s 33ms/step - loss: 0.3784 - accuracy: 0.8241 - val_loss: 0.2836 - val_accuracy: 0.8813\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 38s 32ms/step - loss: 0.2386 - accuracy: 0.9029 - val_loss: 0.2837 - val_accuracy: 0.8819\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 38s 33ms/step - loss: 0.1570 - accuracy: 0.9408 - val_loss: 0.3136 - val_accuracy: 0.8770\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 38s 33ms/step - loss: 0.0816 - accuracy: 0.9728 - val_loss: 0.3991 - val_accuracy: 0.8714\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 38s 32ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.5314 - val_accuracy: 0.8672\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 38s 32ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.5409 - val_accuracy: 0.8713\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 44s 37ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.7284 - val_accuracy: 0.8556\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 41s 35ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.6449 - val_accuracy: 0.8686\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 41s 35ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.7437 - val_accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 38s 32ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.7237 - val_accuracy: 0.8693\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.7237 - accuracy: 0.8693\n",
      "CNN Model with 2 conv layers and 1 dense layers Accuracy: 86.93%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 40s 33ms/step - loss: 0.3876 - accuracy: 0.8167 - val_loss: 0.2998 - val_accuracy: 0.8730\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 38s 32ms/step - loss: 0.2402 - accuracy: 0.9027 - val_loss: 0.3100 - val_accuracy: 0.8762\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 38s 32ms/step - loss: 0.1620 - accuracy: 0.9379 - val_loss: 0.3224 - val_accuracy: 0.8775\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 42s 36ms/step - loss: 0.0936 - accuracy: 0.9681 - val_loss: 0.3675 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 40s 34ms/step - loss: 0.0515 - accuracy: 0.9846 - val_loss: 0.5074 - val_accuracy: 0.8686\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 40s 34ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.5608 - val_accuracy: 0.8698\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 41s 35ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.5782 - val_accuracy: 0.8654\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 42s 36ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.6173 - val_accuracy: 0.8712\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 40s 34ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.5965 - val_accuracy: 0.8714\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 41s 35ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.6929 - val_accuracy: 0.8690\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.6929 - accuracy: 0.8690\n",
      "CNN Model with 2 conv layers and 2 dense layers Accuracy: 86.90%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 49s 40ms/step - loss: 0.3951 - accuracy: 0.8107 - val_loss: 0.3197 - val_accuracy: 0.8629\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 47s 40ms/step - loss: 0.2478 - accuracy: 0.9007 - val_loss: 0.2955 - val_accuracy: 0.8741\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 46s 39ms/step - loss: 0.1757 - accuracy: 0.9347 - val_loss: 0.3108 - val_accuracy: 0.8778\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 45s 39ms/step - loss: 0.1088 - accuracy: 0.9636 - val_loss: 0.3472 - val_accuracy: 0.8712\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 45s 38ms/step - loss: 0.0635 - accuracy: 0.9797 - val_loss: 0.4734 - val_accuracy: 0.8701\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 40s 34ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.4638 - val_accuracy: 0.8695\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 40s 34ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 0.5450 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 46s 40ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.6631 - val_accuracy: 0.8660\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 44s 38ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 0.5967 - val_accuracy: 0.8724\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 40s 34ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 0.6620 - val_accuracy: 0.8687\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.6620 - accuracy: 0.8687\n",
      "CNN Model with 2 conv layers and 3 dense layers Accuracy: 86.87%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 61s 51ms/step - loss: 0.3967 - accuracy: 0.8147 - val_loss: 0.3024 - val_accuracy: 0.8718\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 60s 51ms/step - loss: 0.2560 - accuracy: 0.8954 - val_loss: 0.2838 - val_accuracy: 0.8790\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 58s 50ms/step - loss: 0.1895 - accuracy: 0.9271 - val_loss: 0.3075 - val_accuracy: 0.8757\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 59s 50ms/step - loss: 0.1194 - accuracy: 0.9570 - val_loss: 0.3720 - val_accuracy: 0.8707\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 58s 50ms/step - loss: 0.0723 - accuracy: 0.9749 - val_loss: 0.4764 - val_accuracy: 0.8599\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 61s 52ms/step - loss: 0.0510 - accuracy: 0.9823 - val_loss: 0.6299 - val_accuracy: 0.8567\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 64s 55ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.5840 - val_accuracy: 0.8621\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 62s 53ms/step - loss: 0.0326 - accuracy: 0.9891 - val_loss: 0.6242 - val_accuracy: 0.8575\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 62s 53ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.7474 - val_accuracy: 0.8613\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 62s 53ms/step - loss: 0.0244 - accuracy: 0.9914 - val_loss: 0.6973 - val_accuracy: 0.8552\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.6973 - accuracy: 0.8552\n",
      "CNN Model with 3 conv layers and 1 dense layers Accuracy: 85.52%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 63s 53ms/step - loss: 0.4217 - accuracy: 0.7881 - val_loss: 0.3089 - val_accuracy: 0.8695\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 61s 52ms/step - loss: 0.2640 - accuracy: 0.8919 - val_loss: 0.2906 - val_accuracy: 0.8795\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 61s 52ms/step - loss: 0.1923 - accuracy: 0.9254 - val_loss: 0.3047 - val_accuracy: 0.8757\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 61s 52ms/step - loss: 0.1243 - accuracy: 0.9558 - val_loss: 0.3708 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 58s 50ms/step - loss: 0.0794 - accuracy: 0.9727 - val_loss: 0.4302 - val_accuracy: 0.8674\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 59s 51ms/step - loss: 0.0547 - accuracy: 0.9819 - val_loss: 0.4915 - val_accuracy: 0.8608\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 58s 49ms/step - loss: 0.0446 - accuracy: 0.9847 - val_loss: 0.5989 - val_accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 59s 50ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 0.6242 - val_accuracy: 0.8582\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 60s 51ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.6828 - val_accuracy: 0.8606\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 59s 50ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.7350 - val_accuracy: 0.8616\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.7350 - accuracy: 0.8616\n",
      "CNN Model with 3 conv layers and 2 dense layers Accuracy: 86.16%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 60s 50ms/step - loss: 0.4452 - accuracy: 0.7849 - val_loss: 0.3295 - val_accuracy: 0.8543\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 58s 50ms/step - loss: 0.2910 - accuracy: 0.8793 - val_loss: 0.3102 - val_accuracy: 0.8751\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 58s 50ms/step - loss: 0.2297 - accuracy: 0.9098 - val_loss: 0.3066 - val_accuracy: 0.8747\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 58s 49ms/step - loss: 0.1719 - accuracy: 0.9363 - val_loss: 0.3600 - val_accuracy: 0.8716\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 58s 49ms/step - loss: 0.1198 - accuracy: 0.9579 - val_loss: 0.3777 - val_accuracy: 0.8649\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 60s 52ms/step - loss: 0.0827 - accuracy: 0.9711 - val_loss: 0.4042 - val_accuracy: 0.8652\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 60s 51ms/step - loss: 0.0539 - accuracy: 0.9820 - val_loss: 0.6143 - val_accuracy: 0.8646\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 58s 50ms/step - loss: 0.0390 - accuracy: 0.9857 - val_loss: 0.6334 - val_accuracy: 0.8584\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 59s 50ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 0.6519 - val_accuracy: 0.8564\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 58s 50ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.6995 - val_accuracy: 0.8592\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.6995 - accuracy: 0.8592\n",
      "CNN Model with 3 conv layers and 3 dense layers Accuracy: 85.92%\n"
     ]
    }
   ],
   "source": [
    "# Testing with 200 max length\n",
    "for num_conv_layers in range(1, 4):\n",
    "    for num_dense_layers in range(1, 4):\n",
    "        model = create_cnn_model(num_conv_layers, num_dense_layers, max_length=200)\n",
    "        model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'CNN Model with {num_conv_layers} conv layers and {num_dense_layers} dense layers Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Performance:\n",
    "\n",
    "CNN Model with 1 conv layers and 1 dense layers\n",
    "\n",
    "Accuracy: 87.98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 39s 33ms/step - loss: 0.3661 - accuracy: 0.8344 - val_loss: 0.2731 - val_accuracy: 0.8860\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 41s 35ms/step - loss: 0.2103 - accuracy: 0.9176 - val_loss: 0.2651 - val_accuracy: 0.8925\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 42s 36ms/step - loss: 0.1143 - accuracy: 0.9609 - val_loss: 0.3068 - val_accuracy: 0.8868\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 43s 36ms/step - loss: 0.0425 - accuracy: 0.9899 - val_loss: 0.3799 - val_accuracy: 0.8851\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.3799 - accuracy: 0.8851\n",
      "CNN Model with 1 conv layers and 1 dense layers Accuracy: 88.51%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 47s 37ms/step - loss: 0.3691 - accuracy: 0.8290 - val_loss: 0.2885 - val_accuracy: 0.8766\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 44s 38ms/step - loss: 0.2044 - accuracy: 0.9204 - val_loss: 0.2673 - val_accuracy: 0.8885\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 66s 57ms/step - loss: 0.1051 - accuracy: 0.9646 - val_loss: 0.3346 - val_accuracy: 0.8829\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: 0.0396 - accuracy: 0.9889 - val_loss: 0.4605 - val_accuracy: 0.8738\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.4605 - accuracy: 0.8738\n",
      "CNN Model with 1 conv layers and 2 dense layers Accuracy: 87.38%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 37s 31ms/step - loss: 0.3820 - accuracy: 0.8229 - val_loss: 0.2680 - val_accuracy: 0.8878\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 37s 32ms/step - loss: 0.2018 - accuracy: 0.9218 - val_loss: 0.2643 - val_accuracy: 0.8926\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 37s 32ms/step - loss: 0.1012 - accuracy: 0.9662 - val_loss: 0.3166 - val_accuracy: 0.8850\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 44s 37ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 0.5825 - val_accuracy: 0.8646\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.5825 - accuracy: 0.8646\n",
      "CNN Model with 1 conv layers and 3 dense layers Accuracy: 86.46%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 119s 98ms/step - loss: 0.3815 - accuracy: 0.8248 - val_loss: 0.2895 - val_accuracy: 0.8763\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 112s 95ms/step - loss: 0.2384 - accuracy: 0.9038 - val_loss: 0.2760 - val_accuracy: 0.8844\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 0.1574 - accuracy: 0.9397 - val_loss: 0.3562 - val_accuracy: 0.8658\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 0.0864 - accuracy: 0.9705 - val_loss: 0.3787 - val_accuracy: 0.8690\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.3787 - accuracy: 0.8690\n",
      "CNN Model with 2 conv layers and 1 dense layers Accuracy: 86.90%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 104s 81ms/step - loss: 0.3986 - accuracy: 0.8065 - val_loss: 0.2920 - val_accuracy: 0.8774\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 90s 76ms/step - loss: 0.2452 - accuracy: 0.9019 - val_loss: 0.2851 - val_accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 90s 77ms/step - loss: 0.1699 - accuracy: 0.9366 - val_loss: 0.2942 - val_accuracy: 0.8857\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 0.0995 - accuracy: 0.9654 - val_loss: 0.3593 - val_accuracy: 0.8768\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 0.3593 - accuracy: 0.8768\n",
      "CNN Model with 2 conv layers and 2 dense layers Accuracy: 87.68%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 92s 77ms/step - loss: 0.4082 - accuracy: 0.8011 - val_loss: 0.3026 - val_accuracy: 0.8731\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 90s 77ms/step - loss: 0.2484 - accuracy: 0.8998 - val_loss: 0.2813 - val_accuracy: 0.8846\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 92s 79ms/step - loss: 0.1742 - accuracy: 0.9365 - val_loss: 0.3118 - val_accuracy: 0.8732\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 91s 78ms/step - loss: 0.1101 - accuracy: 0.9624 - val_loss: 0.3372 - val_accuracy: 0.8778\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 0.3372 - accuracy: 0.8778\n",
      "CNN Model with 2 conv layers and 3 dense layers Accuracy: 87.78%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 138s 116ms/step - loss: 0.3979 - accuracy: 0.8139 - val_loss: 0.3058 - val_accuracy: 0.8690\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 139s 118ms/step - loss: 0.2595 - accuracy: 0.8959 - val_loss: 0.2839 - val_accuracy: 0.8845\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 153s 130ms/step - loss: 0.1944 - accuracy: 0.9259 - val_loss: 0.3090 - val_accuracy: 0.8813\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 237s 202ms/step - loss: 0.1295 - accuracy: 0.9524 - val_loss: 0.3531 - val_accuracy: 0.8723\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 29s 73ms/step - loss: 0.3531 - accuracy: 0.8723\n",
      "CNN Model with 3 conv layers and 1 dense layers Accuracy: 87.23%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 228s 191ms/step - loss: 0.4131 - accuracy: 0.7952 - val_loss: 0.2980 - val_accuracy: 0.8730\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 203s 173ms/step - loss: 0.2565 - accuracy: 0.8966 - val_loss: 0.2842 - val_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 169s 144ms/step - loss: 0.1901 - accuracy: 0.9280 - val_loss: 0.3301 - val_accuracy: 0.8737\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 140s 120ms/step - loss: 0.1266 - accuracy: 0.9549 - val_loss: 0.3569 - val_accuracy: 0.8730\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.3569 - accuracy: 0.8730\n",
      "CNN Model with 3 conv layers and 2 dense layers Accuracy: 87.30%\n",
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 139s 117ms/step - loss: 0.4432 - accuracy: 0.7942 - val_loss: 0.3269 - val_accuracy: 0.8582\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 154s 132ms/step - loss: 0.2812 - accuracy: 0.8875 - val_loss: 0.3171 - val_accuracy: 0.8734\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 74944s 64s/step - loss: 0.2161 - accuracy: 0.9174 - val_loss: 0.3518 - val_accuracy: 0.8677\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 229s 196ms/step - loss: 0.1597 - accuracy: 0.9431 - val_loss: 0.3419 - val_accuracy: 0.8675\n",
      "Epoch 4: early stopping\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3419 - accuracy: 0.8675\n",
      "CNN Model with 3 conv layers and 3 dense layers Accuracy: 86.75%\n"
     ]
    }
   ],
   "source": [
    "# Testing with 500 max length \n",
    "for num_conv_layers in range(1, 4):\n",
    "    for num_dense_layers in range(1, 4):\n",
    "        model = create_cnn_model(num_conv_layers, num_dense_layers, max_length=500)\n",
    "        model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'CNN Model with {num_conv_layers} conv layers and {num_dense_layers} dense layers Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance:\n",
    "\n",
    "CNN Model with 1 conv layers and 1 dense layers \n",
    "\n",
    "Accuracy: 88.51%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: summarize and visualize the results discovered from the analysis\n",
    "\n",
    "Please use figures or tables to present the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN (500, 1, 1)</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN (200, 1, 1)</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP (100, 50)</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN (10)</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN (5)</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Test Accuracy\n",
       "0  Logistic Regression          0.890\n",
       "1           Linear SVC          0.890\n",
       "6      CNN (500, 1, 1)          0.885\n",
       "5      CNN (200, 1, 1)          0.880\n",
       "4        MLP (100, 50)          0.870\n",
       "3             KNN (10)          0.790\n",
       "2              KNN (5)          0.780"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Model': ['Logistic Regression', 'Linear SVC', 'KNN (5)', 'KNN (10)', 'MLP (100, 50)', 'CNN (200, 1, 1)', 'CNN (500, 1, 1)'],\n",
    "    'Test Accuracy': [0.89, 0.89, 0.78, 0.79, 0.87, 0.88, 0.885]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort the df by test accuracy\n",
    "df = df.sort_values(by='Test Accuracy', ascending=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating bar plot to visualize test accuracy\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(df['Model'], df['Test Accuracy'], color='skyblue')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Test Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the model accuracy df and bar plot, we can rank the models in descending order by:\n",
    "\n",
    "1. Log Regresstion\n",
    "2. Linear SVC\n",
    "3. CNN (500,1,1)\n",
    "4. CNN (200,1,1)\n",
    "5. MLP (100,50)\n",
    "6. KNN (10)\n",
    "7. KNN (5)\n",
    "\n",
    "The top 5 models all perform relatively well, then a dropoff showing the KNN models performing worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to show the functionality of the program, a user is able to input a custom review to check the accuracy of the models. The input will be preprocessed and each model will predict the sentiment of the inputted review. \n",
    "\n",
    "We will not include the CNN model since it requires different processing than the other models. Furthermore, the optimal CNN model was not explicitally defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This was a great movie.\n",
      "Logistic Regression Prediction: [1]\n",
      "Linear SVC Prediction: [1]\n",
      "KNN Prediction: [1]\n",
      "MLP Prediction: [1]\n",
      "---------------------------------\n",
      "Review: This was a bad movie\n",
      "Logistic Regression Prediction: [0]\n",
      "Linear SVC Prediction: [0]\n",
      "KNN Prediction: [0]\n",
      "MLP Prediction: [0]\n",
      "---------------------------------\n",
      "Review: At first I hated this movie, but the ending made me love it!\n",
      "Logistic Regression Prediction: [1]\n",
      "Linear SVC Prediction: [1]\n",
      "KNN Prediction: [0]\n",
      "MLP Prediction: [1]\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "review = input(\"Enter a review. Type 'q' to exit: \")\n",
    "\n",
    "while review != 'q':\n",
    "    print(f'Review: {review}')\n",
    "\n",
    "    # Preprocess the review\n",
    "    review = preprocess_text(review)\n",
    "\n",
    "    # Convert the review into Tfidf form\n",
    "    review = vectorizer.transform([review])\n",
    "\n",
    "    # Make predictions for each model\n",
    "    lr_pred = lr_model.predict(review)\n",
    "    svc_pred = svc_model.predict(review)\n",
    "    knn_pred = knn_model.predict(review)\n",
    "    mlp_pred = mlp_model.predict(review)\n",
    "\n",
    "    # Print the predictions\n",
    "    print(f'Logistic Regression Prediction: {lr_pred}')\n",
    "    print(f'Linear SVC Prediction: {svc_pred}')\n",
    "    print(f'KNN Prediction: {knn_pred}')\n",
    "    print(f'MLP Prediction: {mlp_pred}')\n",
    "    print('---------------------------------')\n",
    "\n",
    "    review = input(\"Enter a review. Type 'q' to exit: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can test different reviews and see how the models react. We see some shortcomings in the KNN model in the last prompt when the review contradicts itself, but each of the other models are still able to decipher the overall sentiment. \n",
    "\n",
    "For straightforward reviews, all models are able to accurately determine whether or not the review is positve or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "**What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this Jupyter notebook. Please make sure all the plotted tables and figures are in the notebook. \n",
    "\n",
    "* **PDF Report**: please prepare a report in the PDF form which should be at least 4 pages. The report should includes:\n",
    "\n",
    "  * Data description and exploration.\n",
    "\n",
    "  * Data preproccessing.\n",
    "\n",
    "  * Data modelling.\n",
    "\n",
    "  * What did you find in the data?\n",
    "\n",
    "  * (please include figures or tables in the report, but no source code)\n",
    "  \n",
    "Please compress all the files in a zipped file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
